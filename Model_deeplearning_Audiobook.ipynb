{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9a725b8-f4e2-49af-a588-7d876f61e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f549b70a-aa1c-4c20-90a3-a49194db3025",
   "metadata": {},
   "source": [
    "audiobook dataset has features like:\n",
    "\n",
    "Book length, Price, Reviews, Ratings, Minutes listened, Completion %, etc.\n",
    "\n",
    "The relationship between these and purchase is not purely linear.\n",
    "For example:\n",
    "\n",
    "A long book doesn’t always mean purchase → depends on whether they finished it, the rating, and price.\n",
    "\n",
    "These kinds of interactions between variables are hard for logistic regression but natural for neural networks.\n",
    "Logistic regression: simple, interpretable, fast, but limited to linear patterns.\n",
    "\n",
    "Deep learning: more powerful, captures complex nonlinear interactions, but needs more data and tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ae77814-2fc3-459f-aa2e-71213fdcf7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are loading the dataset and defining the features and target\n",
    "\n",
    "df=pd.read_csv('audioboook_scaled.csv')\n",
    "x=df.drop(\"Target\",axis=1)\n",
    "y=df['Target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a334369-b05e-485f-b078-6c76ed482b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc758b35-b20c-4020-9c3d-fc860b9f4d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\anaconda3\\envs\\fresh_env\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Now we can build a neural network\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "#Nowe we can define a model\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(x_train.shape[1],)),  # hidden layer 1\n",
    "    Dropout(0.3),  # regularization to prevent overfitting\n",
    "    Dense(32, activation='relu'),  # hidden layer 2\n",
    "    Dense(1, activation='sigmoid')  # output layer (binary classification)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef6d1bd-43b9-47f0-96ba-b0560c158691",
   "metadata": {},
   "source": [
    "Dense(64, activation='relu') → first hidden layer with 64 neurons.\n",
    "\n",
    "Dropout(0.3) → randomly drops 30% of neurons during training (to reduce overfitting).\n",
    "\n",
    "Dense(1, activation='sigmoid') → output layer (gives probability between 0 and 1).\n",
    "\n",
    "binary_crossentropy → loss function for binary classification.\n",
    "\n",
    "adam → adaptive optimizer that works well in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e31da10e-67ba-4b04-a015-aac3a31dde64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8387 - loss: 0.4202 - val_accuracy: 0.8974 - val_loss: 0.2868\n",
      "Epoch 2/20\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8991 - loss: 0.2772 - val_accuracy: 0.9049 - val_loss: 0.2627\n",
      "Epoch 3/20\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8998 - loss: 0.2620 - val_accuracy: 0.9038 - val_loss: 0.2558\n",
      "Epoch 4/20\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8973 - loss: 0.2651 - val_accuracy: 0.9056 - val_loss: 0.2533\n",
      "Epoch 5/20\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9105 - loss: 0.2420 - val_accuracy: 0.9081 - val_loss: 0.2470\n",
      "Epoch 6/20\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9052 - loss: 0.2484 - val_accuracy: 0.8981 - val_loss: 0.2508\n",
      "Epoch 7/20\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9039 - loss: 0.2451 - val_accuracy: 0.9081 - val_loss: 0.2422\n",
      "Epoch 8/20\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9056 - loss: 0.2459 - val_accuracy: 0.9049 - val_loss: 0.2443\n",
      "Epoch 9/20\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.2359 - val_accuracy: 0.9066 - val_loss: 0.2424\n",
      "Epoch 10/20\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9084 - loss: 0.2398 - val_accuracy: 0.9088 - val_loss: 0.2379\n",
      "Epoch 11/20\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9113 - loss: 0.2308 - val_accuracy: 0.9088 - val_loss: 0.2350\n",
      "Epoch 12/20\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9137 - loss: 0.2297 - val_accuracy: 0.9088 - val_loss: 0.2368\n",
      "Epoch 13/20\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9097 - loss: 0.2282 - val_accuracy: 0.9098 - val_loss: 0.2345\n",
      "Epoch 14/20\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9101 - loss: 0.2348 - val_accuracy: 0.9088 - val_loss: 0.2360\n",
      "Epoch 15/20\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9124 - loss: 0.2226 - val_accuracy: 0.9102 - val_loss: 0.2334\n",
      "Epoch 16/20\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9139 - loss: 0.2252 - val_accuracy: 0.9095 - val_loss: 0.2333\n",
      "Epoch 17/20\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9150 - loss: 0.2247 - val_accuracy: 0.9091 - val_loss: 0.2333\n",
      "Epoch 18/20\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9123 - loss: 0.2284 - val_accuracy: 0.9088 - val_loss: 0.2347\n",
      "Epoch 19/20\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9142 - loss: 0.2258 - val_accuracy: 0.9098 - val_loss: 0.2306\n",
      "Epoch 20/20\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9048 - loss: 0.2335 - val_accuracy: 0.9095 - val_loss: 0.2301\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d860a36-cc35-4a47-b982-88542187e54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Accuracy : 0.9094781682641108\n",
      "Precision : 0.9615384615384616\n",
      "Recall : 0.44742729306487694\n",
      "F1 Score : 0.6106870229007634\n",
      "ROC AUC : 0.9043166350446955\n",
      "\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2370\n",
      "           1       0.96      0.45      0.61       447\n",
      "\n",
      "    accuracy                           0.91      2817\n",
      "   macro avg       0.93      0.72      0.78      2817\n",
      "weighted avg       0.91      0.91      0.90      2817\n",
      "\n",
      "Confusion Matrix :\n",
      " [[2362    8]\n",
      " [ 247  200]]\n"
     ]
    }
   ],
   "source": [
    "#Let's Evaluate the model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Predictions\n",
    "y_pred = (model.predict(x_test) > 0.5).astype(\"int32\")   # threshold 0.5\n",
    "y_prob = model.predict(x_test)                          # probabilities\n",
    "\n",
    "# Evaluation Metrics\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision :\", precision_score(y_test, y_pred))\n",
    "print(\"Recall :\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score :\", f1_score(y_test, y_pred))\n",
    "print(\"ROC AUC :\", roc_auc_score(y_test, y_prob))\n",
    "\n",
    "print(\"\\nClassification Report :\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix :\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59d9dace-40f1-443a-b3f8-ab77029ac707",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similar to that of Logistic regression once again 1 is underrepresented, So let's try SMOTE now\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3c06da-b24f-4b73-bf7b-e0bc57a93c36",
   "metadata": {},
   "source": [
    "we should consider SMOTE when:\n",
    "Class imbalance exists (like 90% vs 10%).\n",
    "You care about minority class prediction (e.g., churn, fraud, disease detection).\n",
    "Traditional oversampling (simply copying minority examples) may cause overfitting.\n",
    "For our audiobook dataset → predicting whether a customer will purchase (Target=1) is more important, so SMOTE is a good choice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d217e4-7739-4a92-9558-47f1488df828",
   "metadata": {},
   "source": [
    "Instead of just copying minority class rows, SMOTE generates new, synthetic but realistic examples. Here’s how:\n",
    "For each minority class data point, SMOTE finds its k nearest neighbors (default k=5).\n",
    "It picks one of those neighbors randomly.\n",
    "It then creates a new synthetic sample somewhere along the line between the two points.\n",
    "\n",
    "SMOTE balances classes by creating synthetic minority samples.\n",
    "Use it when you care about the minority class performance (recall, F1).\n",
    "It makes the model less biased and improves detection of rare events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee04ac65-84d0-4cf1-8e83-10c915b42f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.12.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\prana\\anaconda3\\envs\\fresh_env\\lib\\site-packages (from imbalanced-learn) (2.0.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\prana\\anaconda3\\envs\\fresh_env\\lib\\site-packages (from imbalanced-learn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\prana\\anaconda3\\envs\\fresh_env\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\prana\\anaconda3\\envs\\fresh_env\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\prana\\anaconda3\\envs\\fresh_env\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Downloading imbalanced_learn-0.12.4-py3-none-any.whl (258 kB)\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.12.4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f78da6e5-df3d-49b7-b1bf-84e1b8c61834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\anaconda3\\envs\\fresh_env\\lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: {0: 9476, 1: 1790}\n",
      "After SMOTE: {np.int64(0): np.int64(9476), np.int64(1): np.int64(9476)}\n"
     ]
    }
   ],
   "source": [
    "#Apply SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "x_train_resampled, y_train_resampled = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "print(\"Before SMOTE:\", y_train.value_counts().to_dict())\n",
    "print(\"After SMOTE:\", dict(zip(*np.unique(y_train_resampled, return_counts=True))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1216d3e6-2ef0-4904-8739-5fc48439396d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8012 - loss: 0.3709 - val_accuracy: 0.8537 - val_loss: 0.3573\n",
      "Epoch 2/20\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8125 - loss: 0.3504 - val_accuracy: 0.8576 - val_loss: 0.3267\n",
      "Epoch 3/20\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8190 - loss: 0.3470 - val_accuracy: 0.8605 - val_loss: 0.3173\n",
      "Epoch 4/20\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8148 - loss: 0.3503 - val_accuracy: 0.8616 - val_loss: 0.3106\n",
      "Epoch 5/20\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8180 - loss: 0.3492 - val_accuracy: 0.8601 - val_loss: 0.3409\n",
      "Epoch 6/20\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8205 - loss: 0.3376 - val_accuracy: 0.8573 - val_loss: 0.3323\n",
      "Epoch 7/20\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8190 - loss: 0.3400 - val_accuracy: 0.8555 - val_loss: 0.3476\n",
      "Epoch 8/20\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8203 - loss: 0.3386 - val_accuracy: 0.8608 - val_loss: 0.3208\n",
      "Epoch 9/20\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8239 - loss: 0.3348 - val_accuracy: 0.8545 - val_loss: 0.3468\n",
      "Epoch 10/20\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8172 - loss: 0.3418 - val_accuracy: 0.8587 - val_loss: 0.3441\n",
      "Epoch 11/20\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8200 - loss: 0.3405 - val_accuracy: 0.8601 - val_loss: 0.3311\n",
      "Epoch 12/20\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8207 - loss: 0.3372 - val_accuracy: 0.8601 - val_loss: 0.3340\n",
      "Epoch 13/20\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8188 - loss: 0.3379 - val_accuracy: 0.8591 - val_loss: 0.3373\n",
      "Epoch 14/20\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8250 - loss: 0.3331 - val_accuracy: 0.8541 - val_loss: 0.3612\n",
      "Epoch 15/20\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8220 - loss: 0.3361 - val_accuracy: 0.8552 - val_loss: 0.3415\n",
      "Epoch 16/20\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8190 - loss: 0.3391 - val_accuracy: 0.8541 - val_loss: 0.3422\n",
      "Epoch 17/20\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8233 - loss: 0.3284 - val_accuracy: 0.8580 - val_loss: 0.3381\n",
      "Epoch 18/20\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8219 - loss: 0.3363 - val_accuracy: 0.8463 - val_loss: 0.3571\n",
      "Epoch 19/20\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8213 - loss: 0.3393 - val_accuracy: 0.8530 - val_loss: 0.3757\n",
      "Epoch 20/20\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8202 - loss: 0.3373 - val_accuracy: 0.8300 - val_loss: 0.3587\n"
     ]
    }
   ],
   "source": [
    "#Retrain with the sampled data \n",
    "\n",
    "history = model.fit(\n",
    "    x_train_resampled, y_train_resampled,\n",
    "    validation_data=(x_test, y_test),  # keep test untouched\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4ed0a08c-6b8f-4541-bafe-bcfa425039e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Accuracy : 0.8821441249556266\n",
      "Precision : 0.6280623608017817\n",
      "Recall : 0.6308724832214765\n",
      "F1 Score : 0.6294642857142857\n",
      "ROC AUC : 0.905415380549184\n"
     ]
    }
   ],
   "source": [
    "#Evaluate again\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "# Apply threshold (default 0.7)\n",
    "y_pred_classes = (y_pred > 0.7).astype(\"int32\")\n",
    "\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred_classes))\n",
    "print(\"Precision :\", precision_score(y_test, y_pred_classes))\n",
    "print(\"Recall :\", recall_score(y_test, y_pred_classes))\n",
    "print(\"F1 Score :\", f1_score(y_test, y_pred_classes))\n",
    "print(\"ROC AUC :\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4a9793-179c-4bdc-b4f4-5db14fd808ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fresh_env)",
   "language": "python",
   "name": "fresh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
